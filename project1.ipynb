{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(\"E:\\\\programs\\\\python\\\\NLP\\\\trainset.csv\", delimiter=',', encoding='utf-8')\n",
    "validationset = pd.read_csv(\"E:\\\\programs\\\\python\\\\NLP\\\\validationset.csv\", delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display complete contents of a dataframe without any kind of truncation\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.width',None)\n",
    "pd.set_option('display.max_colwidth',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1  archive_by_user                   brand  \\\n",
      "0  0           282086        True             NaN                      \n",
      "1  1           762753        True             Samsung::سامسونگ         \n",
      "2  2           805240        True             NaN                      \n",
      "3  3           556730        False            NaN                      \n",
      "4  4           727332        True             NaN                      \n",
      "5  5           805039        True             NaN                      \n",
      "6  6           812617        False            NaN                      \n",
      "7  7           295730        True             NaN                      \n",
      "8  8           777605        False            نیسان::Nissan            \n",
      "9  9           797079        False            پراید صندوق‌دار::Pride   \n",
      "\n",
      "                 cat1                       cat2            cat3     city  \\\n",
      "0  personal            clothing-and-shoes         shoes-belt-bag  Tehran    \n",
      "1  electronic-devices  mobile-tablet              mobile-phones   Tehran    \n",
      "2  personal            jewelry-and-watches        watches         Tehran    \n",
      "3  personal            baby-and-toys              personal-toys   Tehran    \n",
      "4  leisure-hobbies     hobby-collectibles         coin-stamp      Tehran    \n",
      "5  leisure-hobbies     sport-leisure              ball-sports     Tehran    \n",
      "6  for-the-home        furniture-and-home-decore  lighting        Tehran    \n",
      "7  vehicles            parts-accessories          NaN             Isfahan   \n",
      "8  vehicles            cars                       light           Shiraz    \n",
      "9  vehicles            cars                       light           Tehran    \n",
      "\n",
      "       created_at  \\\n",
      "0  Monday 11AM      \n",
      "1  Wednesday 12PM   \n",
      "2  Tuesday 09AM     \n",
      "3  Thursday 06PM    \n",
      "4  Wednesday 09PM   \n",
      "5  Tuesday 11AM     \n",
      "6  Thursday 08AM    \n",
      "7  Monday 10PM      \n",
      "8  Wednesday 01PM   \n",
      "9  Tuesday 03PM     \n",
      "\n",
      "                                                                                                                                                                          desc  \\\n",
      "0  چکمه یکبار پوشیده شده قیمت 42\\nکفش قهوه ای سوخته هشتگ نو قیمت 27\\nکفش گیپوری شیشه ای قیمت 25 با کفی به 39 میشه و بدون کفی به 40 و نو نو\\nامکان پست\\nمزاحمت مستقیما پلیس فتا   \n",
      "1  گوشی رو تا حالا باز نکردم و تو جعبه پلمپه از دیجی کالا برام گرفتنش با گارانتی مایروتل  قیمتش تو دیجی ۹۳۰ تومن                                                                 \n",
      "2  ساعت هیچ مشکلی ندارد اصل اصل هستش چون دیگه دستم نمیکنم میخوام بفروشم                                                                                                          \n",
      "3  دوچرخه از هرلحاظ سالمه و فقط مدت کوتاهی استفاده شده.به خریدار واقعی تخفیف هم میدم                                                                                             \n",
      "4  14 اسکناس مطابق تصویر همه باهم 200 هزار تومان\\nمناسب کلکسیونر و مجموعه دار.\\nفقط خریدار واقعی زنگ بزنه ، پیامک نمیتونم جواب بدم$NUM                                           \n",
      "5  فوتبال دستی حرفه ای تاشو درحد نو فقط 2ماه استفاده شده                                                                                                                         \n",
      "6  لوستر نو برای اتاق کودک                                                                                                                                                       \n",
      "7  4 عدد رینگ اهنی ال 90 سالم قیمت از شما من فروشنده هستم با بارند ال 90 هم معاوضه میکنم                                                                                         \n",
      "8  بیمه تا۹۵/۹/۲۷,کف دستی رنگ درعقب                                                                                                                                              \n",
      "9  عقب وجلوپلمب بیرنگ لاستیک نو به شرط مصرف کننده.تماس صبح                                                                                                                       \n",
      "\n",
      "               id  image_count   mileage platform     price  \\\n",
      "0  12875614029625  3           NaN        mobile   42000      \n",
      "1  16051997226596  0           NaN        mobile   850000     \n",
      "2  51715717387979  2           NaN        mobile   130000     \n",
      "3  9381204619687   2           NaN        mobile   200000     \n",
      "4  47687757949429  3           NaN        web     -1          \n",
      "5  35888748102799  3           NaN        mobile   480000     \n",
      "6  61553946516880  1           NaN        mobile   25000      \n",
      "7  21090520055338  0           NaN        mobile  -1          \n",
      "8  27046580911179  2            380000.0  mobile   40000000   \n",
      "9  42106059496341  0            109000.0  mobile   14000000   \n",
      "\n",
      "                                      title   type  year  \n",
      "0  سایز 40                                   women  NaN   \n",
      "1  گوشی سامسونگ a3 2016                      NaN    NaN   \n",
      "2  ساعت زنانه اسپریت اصل                     NaN    NaN   \n",
      "3  فروش یک عدد دوچرخه مارک پرادو بسیار سالم  NaN    NaN   \n",
      "4  14 اسکناس کلکسیونی code1                  NaN    NaN   \n",
      "5  فوتبال دستی حرفه ای                       NaN    NaN   \n",
      "6  لوستر                                     NaN    NaN   \n",
      "7  رینگ اهنی ال 90                           NaN    NaN   \n",
      "8  نیسان سرانزا مدل۸۳                        NaN    1383  \n",
      "9  پراید سفید                                NaN    1390  \n"
     ]
    }
   ],
   "source": [
    "print(trainset.head(10)) # print 10 first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = trainset['Unnamed: 0'].count() #the first row is the topics so we got 700000 data\n",
    "valid_len = validationset['Unnamed: 0'].count()  #the first row is the topics so we got 147635 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700000\n",
      "147635\n"
     ]
    }
   ],
   "source": [
    "print(train_len) #printing the data rows in trainset\n",
    "print(valid_len) #printing the data rows in validationset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_per_cat = trainset.groupby(\"cat1\")[\"id\"].count() #calculating the number of items in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat1\n",
       "businesses            45660 \n",
       "electronic-devices    122905\n",
       "for-the-home          214955\n",
       "leisure-hobbies       61676 \n",
       "personal              102804\n",
       "vehicles              152000\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_per_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = pd.read_csv(\"E:\\\\programs\\\\python\\\\NLP\\\\projects\\\\persian.csv\", sep=\"\\n\", encoding='utf-8')\n",
    "stop_words = arr.values.tolist() #converting the stop words into a list\n",
    "stop_words = [item for sublist in stop_words for item in sublist] #converting stop words into a 1d list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = trainset['desc']\n",
    "titles = trainset['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    چکمه یکبار پوشیده شده قیمت 42\\nکفش قهوه ای سوخته هشتگ نو قیمت 27\\nکفش گیپوری شیشه ای قیمت 25 با کفی به 39 میشه و بدون کفی به 40 و نو نو\\nامکان پست\\nمزاحمت مستقیما پلیس فتا\n",
       "1    گوشی رو تا حالا باز نکردم و تو جعبه پلمپه از دیجی کالا برام گرفتنش با گارانتی مایروتل  قیمتش تو دیجی ۹۳۰ تومن                                                              \n",
       "2    ساعت هیچ مشکلی ندارد اصل اصل هستش چون دیگه دستم نمیکنم میخوام بفروشم                                                                                                       \n",
       "Name: desc, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions.head(3) #printing the first 3 rows of description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = descriptions.head(5) # first 5 rows of description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    \"\"\"\n",
    "     This method takes an unprocessed text and removes its stop words, and punctuations. It takes a list of simple texts and \n",
    "     returns a list containing words that are processed for each text.\n",
    "     text: the unprocessed text\n",
    "     cleared_text: the processed text\n",
    "    \"\"\"\n",
    "    processed_description = [] #the processed descriptions would go here\n",
    "    cleared_text = [] #a list to save all of the processed descriptions\n",
    "    for i in range(len(text)):\n",
    "        desc = text[i]\n",
    "        words = desc.split(\" \")\n",
    "        \n",
    "#     print(len(words))\n",
    "        for j in range(len(words)):\n",
    "            if words[j] not in stop_words:\n",
    "                processed_description.append(words[j])\n",
    "#     print(words)\n",
    "#     print(\"======================================\")\n",
    "#     print(len(processed_description))\n",
    "#         print(processed_description)\n",
    "        cleared_text.append(processed_description)\n",
    "#         print(cleared_text)\n",
    "        processed_description = []\n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['چکمه', 'یکبار', 'پوشیده', 'شده', 'قیمت', '42\\nکفش', 'قهوه', 'ای', 'سوخته', 'هشتگ', 'نو', 'قیمت', '27\\nکفش', 'گیپوری', 'شیشه', 'ای', 'قیمت', '25', 'با', 'کفی', 'به', '39', 'میشه', 'و', 'بدون', 'کفی', 'به', '40', 'و', 'نو', 'نو\\nامکان', 'پست\\nمزاحمت', 'مستقیما', 'پلیس', 'فتا'], ['گوشی', 'رو', 'تا', 'حالا', 'باز', 'نکردم', 'و', 'تو', 'جعبه', 'پلمپه', 'از', 'دیجی', 'کالا', 'برام', 'گرفتنش', 'با', 'گارانتی', 'مایروتل', '', 'قیمتش', 'تو', 'دیجی', '۹۳۰', 'تومن'], ['ساعت', 'هیچ', 'مشکلی', 'ندارد', 'اصل', 'اصل', 'هستش', 'چون', 'دیگه', 'دستم', 'نمیکنم', 'میخوام', 'بفروشم'], ['دوچرخه', 'از', 'هرلحاظ', 'سالمه', 'و', 'فقط', 'مدت', 'کوتاهی', 'استفاده', 'شده.به', 'خریدار', 'واقعی', 'تخفیف', 'هم', 'میدم'], ['14', 'اسکناس', 'مطابق', 'تصویر', 'همه', 'باهم', '200', 'هزار', 'تومان\\nمناسب', 'کلکسیونر', 'و', 'مجموعه', 'دار.\\nفقط', 'خریدار', 'واقعی', 'زنگ', 'بزنه', '،', 'پیامک', 'نمیتونم', 'جواب', 'بدم$NUM']]\n",
      "========================\n",
      "[['چکمه', 'یکبار', 'پوشیده', 'قیمت', '42\\nکفش', 'قهوه', 'سوخته', 'هشتگ', 'نو', 'قیمت', '27\\nکفش', 'گیپوری', 'شیشه', 'قیمت', '25', 'کفی', '39', 'میشه', 'کفی', '40', 'نو', 'نو\\nامکان', 'پست\\nمزاحمت', 'پلیس', 'فتا'], ['گوشی', 'نکردم', 'جعبه', 'پلمپه', 'دیجی', 'کالا', 'برام', 'گرفتنش', 'گارانتی', 'مایروتل', '', 'قیمتش', 'دیجی', '۹۳۰', 'تومن'], ['ساعت', 'مشکلی', 'اصل', 'اصل', 'هستش', 'دستم', 'نمیکنم', 'میخوام', 'بفروشم'], ['دوچرخه', 'هرلحاظ', 'سالمه', 'کوتاهی', 'شده.به', 'خریدار', 'تخفیف', 'میدم'], ['14', 'اسکناس', 'مطابق', 'تصویر', 'باهم', '200', 'تومان\\nمناسب', 'کلکسیونر', 'مجموعه', 'دار.\\nفقط', 'خریدار', 'زنگ', 'بزنه', 'پیامک', 'نمیتونم', 'جواب', 'بدم$NUM']]\n"
     ]
    }
   ],
   "source": [
    "uncleared_text = [] #an example to show how the preprocessing works\n",
    "for i in range(len(sample)):\n",
    "    desc = sample[i]\n",
    "    words = desc.split(\" \")\n",
    "    uncleared_text.append(words)\n",
    "print(uncleared_text) #unprocessed text for the first five rows\n",
    "print(\"========================\")\n",
    "cleared_text = preprocessing(sample)\n",
    "print(cleared_text) #processed text for the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_descriptions = preprocessing(descriptions.head(1000)) #preprocessed descriptions\n",
    "cleared_titles = preprocessing(titles.head(1000)) #preprocessed titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "number_of_texts = len(cleared_titles) #total number of texts in our corpus\n",
    "print(number_of_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(text):\n",
    "    \"\"\"\n",
    "     This method calculates the tf_idf which is tf(word, text) * idf(word). With tf_idf we represent texts in numerical forms\n",
    "     text: the text in which we calculate the tf_idf for.\n",
    "     returns a vector containing the tf_idf for all of the words in the list text\n",
    "    \"\"\"\n",
    "    vector = []\n",
    "    length_of_text = len(text) #the number of words in our text\n",
    "    for i in range(length_of_text):\n",
    "        word = text[i] #put the ith word of text into the variable word\n",
    "        vector.append(tf(word, text) * idf(word, cleared_descriptions))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, text):\n",
    "    \"\"\"\n",
    "     This method calculates the tf which is the number of times the word occurs in a text on the number of words in the text.\n",
    "     word: the word we are calculating tf for\n",
    "     text: the text in which we calculate the tf for word\n",
    "    \"\"\"\n",
    "    number_of_occurances_in_text = 0 #number of times the word occurs in the text\n",
    "    number_of_words_in_text = len(text) #total number of words in the text\n",
    "    for i in range(number_of_words_in_text): #loop over the list text and count the number of occurances of the word\n",
    "        if text[i] == word:\n",
    "            number_of_occurances_in_text += 1\n",
    "            \n",
    "    return (number_of_occurances_in_text/number_of_words_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word, docs):\n",
    "    \"\"\"\n",
    "     This method calculates the idf which is the logarithm (number of text in the corpus/number of texts where the word occurs).\n",
    "     word: the word we are calculating idf for\n",
    "     docs: all of our texts or documents\n",
    "    \"\"\"\n",
    "    number_of_texts = len(docs) #total number of texts in our corpus\n",
    "    number_of_texts_where_the_word_occurs = 0 #number of texts where the word occurs in the corpus\n",
    "    for i in range(number_of_texts): #loop over all the documents or texts in the corpus and count the number of occurances of the word in corpus\n",
    "        if word in docs[i]:\n",
    "            number_of_texts_where_the_word_occurs += 1\n",
    "    return (math.log((1 + number_of_texts)/(1 + number_of_texts_where_the_word_occurs)) + 1) #applying smoothing   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ساعت', 'مشکلی', 'اصل', 'اصل', 'هستش', 'دستم', 'نمیکنم', 'میخوام', 'بفروشم']\n"
     ]
    }
   ],
   "source": [
    "print(cleared_descriptions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "print(tf('اصل', cleared_descriptions[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.864232341591798\n"
     ]
    }
   ],
   "source": [
    "print(idf('اصل',cleared_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numerical_title = cleared_titles # the list of processed words from the title to feed our model with\n",
    "non_numerical_description = cleared_descriptions # the list of processed words from the descriptions to feed our model with\n",
    "#Y is our actual values for cat1\n",
    "non_numerical_Y = trainset['cat1'].head(1000) # we want to predict the cat1 with the title and description that we have for each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizer(category):\n",
    "    \"\"\"\n",
    "    This method will get the list of words for categories and assigns some integer values to them instead. The integer values\n",
    "    are as the following:\n",
    "    businesses ==> 0\n",
    "    electronic-devices ==> 1\n",
    "    for-the-home ==> 2\n",
    "    leisure-hobbies ==>3\n",
    "    personal ==> 4\n",
    "    vehicles ==> 5\n",
    "    \"\"\"\n",
    "    classes = []\n",
    "    category_length = len(category)\n",
    "    for i in range(category_length):\n",
    "        if category[i] == \"businesses\":\n",
    "            classes.append(0)\n",
    "            \n",
    "        elif category[i] == \"electronic-devices\":\n",
    "            classes.append(1)\n",
    "            \n",
    "        elif category[i] == \"for-the-home\":\n",
    "            classes.append(2)\n",
    "            \n",
    "        elif category[i] == \"leisure-hobbies\":\n",
    "            classes.append(3)\n",
    "            \n",
    "        elif category[i] == \"personal\":\n",
    "            classes.append(4)\n",
    "            \n",
    "        else:\n",
    "            classes.append(5)\n",
    "            \n",
    "    return classes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in here we are going to create  a simple x for each text sample\n",
    "def get_numerical_features(non_numerical_title, non_numerical_description):\n",
    "    \"\"\"\n",
    "    This method returns the numerical features for the texts. One simple X for each text sample\n",
    "    \"\"\"\n",
    "    numerical_title = []\n",
    "    numerical_description = []\n",
    "    for i in range(len(non_numerical_title)): #calculating a simple X for each text sample \n",
    "        numerical_title.append(np.mean(tf_idf(non_numerical_title[i])))\n",
    "        numerical_description.append(np.mean(tf_idf(non_numerical_description[i])))\n",
    "        \n",
    "    return numerical_title, numerical_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list containing numerical title and description for each text sample in the training set\n",
    "titles, descriptions = get_numerical_features(non_numerical_title, non_numerical_description) \n",
    "Y = categorizer(non_numerical_Y) #A list containing an integer for the category in cat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6935211104277985   0.30077919597371894   4\n",
      "1.600572071464723   0.4815505016279709   1\n",
      "1.4876878085472134   0.7793919257670185   4\n",
      "0.6676011863569481   0.7048607115853699   4\n",
      "1.8398621587452915   0.37883513632745447   3\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): #printing first 5 rows of X and their Corresponding Y\n",
    "    print(titles[i],\" \", descriptions[i],\" \" ,Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal   4\n",
      "electronic-devices   1\n",
      "personal   4\n",
      "personal   4\n",
      "leisure-hobbies   3\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): #show some of the cat1 and their classes\n",
    "    print(non_numerical_Y[i],\" \" ,Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the trainset into training set and test set. We need to create a test set out of our training\n",
    "# set in order to update our model. In each itertion, we create a new test set out of our trainset and will try to predict them\n",
    "# to see that is our model is good enough to go against the validationset.\n",
    "# After the model is created, we go against the validation set with y = mx + b\n",
    "# train_test_split, Splits arrays or matrices into random train and test subsets\n",
    "\n",
    "# X_train : the training data out of our training set, used to train our model in each iteration\n",
    "\n",
    "# X_test : the desired outputs for the X_train, used to train our model in each iteration \n",
    "\n",
    "# Y_train : part of the trainset that we seperate and use to predict Y_test to see if our model is good enough. If the model still\n",
    "# is not good enough, then we update m and b of the linear function to predict better in the next iteration\n",
    "\n",
    "# Y_test : the desired outputs for the Y_train. we compare these with the prediction of our model based on Y_train to calculate accuracy.\n",
    "# if the accuracy is good enough, then the model is ready and we're done! \n",
    "\n",
    "#the following are all lists\n",
    "title_train, title_test, description_train, description_test, Y_train, Y_test = train_test_split(\n",
    "        titles, descriptions, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.152172834584008 1.6168620465531882 0.4142020582760249 0.47727722177441445 4 2\n",
      "2.1972245132626926 1.3463276148926013 0.5798361472661884 0.46696302756873126 5 0\n",
      "2.6506434502553637 1.7461010254204858 1.8039018996888188 0.630088776491206 5 2\n",
      "1.0201267875989601 2.3698187850163657 1.303880056231026 0.7088518356933293 5 2\n",
      "2.167417403641062 1.3503612724636997 0.5001951235950429 0.44082659674614566 5 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(title_train[i], title_test[i], description_train[i], description_test[i], Y_train[i], Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800   200   800   200   800   200\n"
     ]
    }
   ],
   "source": [
    "print(len(title_train),\" \",len(title_test),\" \" ,len(description_train), \" \",len(description_test), \" \",len(Y_train), \" \",len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_businesses(classes):\n",
    "    \"\"\"\n",
    "    This method returns a list which contains one as an element, whenever the cat1 is business for that data and is zero otherwise\n",
    "    \"\"\"\n",
    "    businesses = []\n",
    "    classes_length = len(classes)\n",
    "    for i in range(classes_length): #loop over the classes and if 0 which means the cat1 is businesses, append 1. append 0 otherwise\n",
    "        if classes[i] == 0:\n",
    "            businesses.append(1)\n",
    "            \n",
    "        else:\n",
    "            businesses.append(0)\n",
    "            \n",
    "    return businesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_electronic_devices(classes):\n",
    "    \"\"\"\n",
    "    This method returns a list which contains one as an element, whenever the cat1 is electronic-devices for that \n",
    "    data and is zero otherwise\n",
    "    \"\"\"\n",
    "    electronics = []\n",
    "    classes_length = len(classes)\n",
    "    for i in range(classes_length): #loop over the classes and if 0 which means the cat1 is businesses, append 1. append 0 otherwise\n",
    "        if classes[i] == 1:\n",
    "            electronics.append(1)\n",
    "            \n",
    "        else:\n",
    "            electronics.append(0)\n",
    "            \n",
    "    return electronics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_for_the_home(classes):\n",
    "    \"\"\"\n",
    "    This method returns a list which contains one as an element, whenever the cat1 is for-the-home \n",
    "    for that data and is zero otherwise\n",
    "    \"\"\"\n",
    "    home = []\n",
    "    classes_length = len(classes)\n",
    "    for i in range(classes_length): #loop over the classes and if 0 which means the cat1 is businesses, append 1. append 0 otherwise\n",
    "        if classes[i] == 2:\n",
    "            home.append(1)\n",
    "            \n",
    "        else:\n",
    "            home.append(0)\n",
    "            \n",
    "    return home\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_leisure_hobbies(classes):\n",
    "    \"\"\"\n",
    "    This method returns a list which contains one as an element, whenever the cat1 is leisure-hobbies \n",
    "    for that data and is zero otherwise\n",
    "    \"\"\"\n",
    "    hobbies = []\n",
    "    classes_length = len(classes)\n",
    "    for i in range(classes_length): #loop over the classes and if 0 which means the cat1 is businesses, append 1. append 0 otherwise\n",
    "        if classes[i] == 3:\n",
    "            hobbies.append(1)\n",
    "            \n",
    "        else:\n",
    "            hobbies.append(0)\n",
    "            \n",
    "    return hobbies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_personal(classes):\n",
    "    \"\"\"\n",
    "    This method returns a list which contains one as an element, whenever the cat1 is personal \n",
    "    for that data and is zero otherwise\n",
    "    \"\"\"\n",
    "    personal = []\n",
    "    classes_length = len(classes)\n",
    "    for i in range(classes_length): #loop over the classes and if 0 which means the cat1 is businesses, append 1. append 0 otherwise\n",
    "        if classes[i] == 4:\n",
    "            personal.append(1)\n",
    "            \n",
    "        else:\n",
    "            personal.append(0)\n",
    "            \n",
    "    return personal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vehicles(classes):\n",
    "    \"\"\"\n",
    "    This method returns a list which contains one as an element, whenever the cat1 is vehicles \n",
    "    for that data and is zero otherwise\n",
    "    \"\"\"\n",
    "    vehicles = []\n",
    "    classes_length = len(classes)\n",
    "    for i in range(classes_length): #loop over the classes and if 0 which means the cat1 is businesses, append 1. append 0 otherwise\n",
    "        if classes[i] == 5:\n",
    "            vehicles.append(1)\n",
    "            \n",
    "        else:\n",
    "            vehicles.append(0)\n",
    "            \n",
    "    return vehicles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the desired outputs for the entire trainset\n",
    "y0 = calculate_businesses(Y_train) #y0 is a list which is one when the cat1 is businesses and zero otherwise\n",
    "y1 = calculate_electronic_devices(Y_train) #y1 is a list which is one when the cat1 is electronic-devices and zero otherwise\n",
    "y2 = calculate_for_the_home(Y_train) #y2 is a list which is one when the cat1 is for-the-home and zero otherwise\n",
    "y3 = calculate_leisure_hobbies(Y_train) #y3 is a list which is one when the cat1 is leisure-hobbies and zero otherwise\n",
    "y4 = calculate_personal(Y_train) #y4 is a list which is one when the cat1 is personal and zero otherwise\n",
    "y5 = calculate_vehicles(Y_train) #y5 is a list which is one when the cat1 is vehicles and zero otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4   0 0 0 0 1 0\n",
      "5   0 0 0 0 0 1\n",
      "5   0 0 0 0 0 1\n",
      "5   0 0 0 0 0 1\n",
      "5   0 0 0 0 0 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): #printing first 5 rows of classes and their respective values in y0 to y5\n",
    "    print(Y_train[i],\" \" , y0[i], y1[i], y2[i], y3[i], y4[i], y5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thes are the desired outputs only for the train part of the trainset in the 6 class of categories\n",
    "#We need these values in order to train our model to predict the X values in the validation set\n",
    "Y_train0 = calculate_businesses(Y_train) #o0 is a list which is one when the cat1 in the Y_train is businesses and zero otherwise\n",
    "Y_train1 = calculate_electronic_devices(Y_train) #o1 is a list which is one when the cat1 in the Y_train is electronic-devices and zero otherwise\n",
    "Y_train2 = calculate_for_the_home(Y_train) #o2 is a list which is one when the cat1 in the Y_train is for-the-home and zero otherwise\n",
    "Y_train3 = calculate_leisure_hobbies(Y_train) #o3 is a list which is one when the cat1 in the Y_train is leisure-hobbies and zero otherwise\n",
    "Y_train4 = calculate_personal(Y_train) #o4 is a list which is one when the cat1 in the Y_train is personal and zero otherwise\n",
    "Y_train5 = calculate_vehicles(Y_train) #o5 is a list which is one when the cat1 in the Y_train is vehicles and zero otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4   0 0 0 0 1 0\n",
      "5   0 0 0 0 0 1\n",
      "5   0 0 0 0 0 1\n",
      "5   0 0 0 0 0 1\n",
      "5   0 0 0 0 0 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):  #printing first 5 rows of classes_of_Y_train and their respective values in Y_train0 to Y_train5\n",
    "    print(Y_train[i],\" \" , Y_train0[i], Y_train1[i], Y_train2[i], Y_train3[i], Y_train4[i], Y_train5[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing logistic regression: <br>\n",
    "Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.15217283 0.41420206]\n",
      "[2.19722451 0.57983615]\n",
      "[2.65064345 1.8039019 ]\n",
      "[1.02012679 1.30388006]\n",
      "[2.1674174  0.50019512]\n",
      "(800, 2)\n",
      "(2,)\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression by determining the features and weights\n",
    "feature = []\n",
    "a = []\n",
    "for i in range(len(title_train)):\n",
    "    a.append(title_train[i])\n",
    "    a.append(description_train[i])\n",
    "    feature.append(a)    \n",
    "    a = []\n",
    "\n",
    "w0 = np.random.uniform(low = 0, high = 1) #initializing the wight0 with a random uniform real number\n",
    "w1 = np.random.uniform(low = 0, high = 1) #initializing the wight1 with a random uniform real number\n",
    "w2 = np.random.uniform(low = 0, high = 1) #initializing the wight2 with a random uniform real number\n",
    "\n",
    "weights = np.array([w1, w2])\n",
    "features = np.array(feature) #features is a 2d numpy array that has title_train as first column and description_train as the second \n",
    "\n",
    "\n",
    "# z = w0 + w1*title + w2*description\n",
    "\n",
    "for i in range(5): #printing some features and their corresponding labels\n",
    "    print(features[i])\n",
    "\n",
    "print(features.shape)\n",
    "print(weights.shape)\n",
    "z = np.dot(features, weights)\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression for businesses\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train0[i]) #businesses\n",
    "actual_business_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_business_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression for electronic_devices\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train1[i]) #electronic_devices\n",
    "actual_electronic_devices_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_electronic_devices_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression for for_the_home\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train2[i]) #for_the_home\n",
    "actual_for_the_home_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_for_the_home_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression for leisure_hobbies\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train3[i]) #leisure_hobbies\n",
    "actual_leisure_hobbies_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_leisure_hobbies_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression for personal\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train4[i]) #personal\n",
    "actual_personal_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_personal_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression for vehicles\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train5[i]) #vehicles\n",
    "actual_vehicles_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_vehicles_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Sigmoid function to map calculated value to a probablity\n",
    "    \"\"\"   \n",
    "    return 1 / (1 + np.exp(-z)) #sigmoid(z) = 1/(1 + e^(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "  '''\n",
    "  Returns 1D array of probabilities\n",
    "  that the class label == 1\n",
    "  '''\n",
    "  z = np.dot(features, weights)\n",
    "  return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predict(features, weights))\n",
    "# print(np.log(predict(features, weights)))\n",
    "# # print(np.log(1 - predict(features, weights)))\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(features, labels, weights):\n",
    "    '''\n",
    "    Using Mean Absolute Error\n",
    "\n",
    "    Features:(400,2)\n",
    "    Labels: (400,1)\n",
    "    Weights:(2,1)\n",
    "    Returns 1D matrix of predictions\n",
    "    Cost = (labels*log(predictions) + (1-labels)*log(1-predictions) ) / len(labels)\n",
    "    '''\n",
    "    observations = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #Take the error when label=1, If label=0, the first side cancels out.\n",
    "    class1_cost = -labels*np.log(predictions) \n",
    "\n",
    "    #Take the error when label=0, If label=1, the second side cancels out. \n",
    "    class2_cost = (1-labels)*np.log(1-predictions) #a negative number\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost #a positive number\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum() / observations\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(features, labels, weights, lr):\n",
    "    '''\n",
    "    Vectorized Gradient Descent\n",
    "\n",
    "    Features:(200, 3)\n",
    "    Labels: (200, 1)\n",
    "    Weights:(3, 1)\n",
    "    '''\n",
    "    N = len(features)\n",
    "\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T,  predictions - labels)\n",
    "\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary(prob):\n",
    "    return 1 if prob >= .5 else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(predictions):\n",
    "    '''\n",
    "    input  - N element array of predictions between 0 and 1\n",
    "    output - N element array of 0s (False) and 1s (True)\n",
    "    '''\n",
    "    predicted_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        predicted_labels.append(decision_boundary(predictions[i]))\n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels, weights, learning_rate, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, learning_rate)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print (\"iter: \",str(i) , \" cost: \",str(cost))\n",
    "\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, actual_labels):\n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict(features, weights)\n",
    "# predicted_labels = classify(predictions) #labels predicted by the classifier\n",
    "# print(predicted_labels)\n",
    "# print(actual_business_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING THE MODELS TO PREDICT EACH CATEGORY (y = w1 x title + w2 x description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.3319393389962942\n",
      "iter:  1000  cost:  0.29407478291248806\n",
      "iter:  2000  cost:  0.29407478286842753\n",
      "iter:  3000  cost:  0.2940747828684273\n",
      "iter:  4000  cost:  0.2940747828684273\n",
      "iter:  5000  cost:  0.2940747828684273\n",
      "iter:  6000  cost:  0.2940747828684273\n",
      "iter:  7000  cost:  0.2940747828684273\n",
      "iter:  8000  cost:  0.2940747828684273\n",
      "iter:  9000  cost:  0.2940747828684273\n"
     ]
    }
   ],
   "source": [
    "business_weights, business_cost_history = train(features, actual_business_labels, weights, 0.35, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_predictions = predict(features, weights)\n",
    "business_predicted_labels = classify(business_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.5446307948517176\n",
      "iter:  1000  cost:  0.49531366437078383\n",
      "iter:  2000  cost:  0.4953136643707839\n",
      "iter:  3000  cost:  0.4953136643707839\n",
      "iter:  4000  cost:  0.4953136643707839\n",
      "iter:  5000  cost:  0.4953136643707839\n",
      "iter:  6000  cost:  0.4953136643707839\n",
      "iter:  7000  cost:  0.4953136643707839\n",
      "iter:  8000  cost:  0.4953136643707839\n",
      "iter:  9000  cost:  0.4953136643707839\n"
     ]
    }
   ],
   "source": [
    "electronic_weights, electronic_cost_history = train(features, actual_electronic_devices_labels, weights, 0.35, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronic_predictions = predict(features, weights)\n",
    "electronic_predicted_labels = classify(electronic_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.6395098071866425\n",
      "iter:  1000  cost:  0.6071848906278104\n",
      "iter:  2000  cost:  0.6071848906278104\n",
      "iter:  3000  cost:  0.6071848906278104\n",
      "iter:  4000  cost:  0.6071848906278104\n",
      "iter:  5000  cost:  0.6071848906278104\n",
      "iter:  6000  cost:  0.6071848906278104\n",
      "iter:  7000  cost:  0.6071848906278104\n",
      "iter:  8000  cost:  0.6071848906278104\n",
      "iter:  9000  cost:  0.6071848906278104\n"
     ]
    }
   ],
   "source": [
    "for_the_home_weights, for_the_home_cost_history = train(features, actual_for_the_home_labels, weights, 0.35, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_the_home_predictions = predict(features, weights)\n",
    "for_the_home_predicted_labels = classify(for_the_home_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.4473105031571346\n",
      "iter:  1000  cost:  0.3665605555663041\n",
      "iter:  2000  cost:  0.3665605492780547\n",
      "iter:  3000  cost:  0.3665605492780526\n",
      "iter:  4000  cost:  0.3665605492780526\n",
      "iter:  5000  cost:  0.3665605492780526\n",
      "iter:  6000  cost:  0.3665605492780526\n",
      "iter:  7000  cost:  0.3665605492780526\n",
      "iter:  8000  cost:  0.3665605492780526\n",
      "iter:  9000  cost:  0.3665605492780526\n"
     ]
    }
   ],
   "source": [
    "hobbies_weights, hobbies_cost_history = train(features, actual_leisure_hobbies_labels, weights, 0.35, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_predictions = predict(features, weights)\n",
    "hobbies_predicted_labels = classify(hobbies_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.5002052850420651\n",
      "iter:  1000  cost:  0.45498903133205965\n",
      "iter:  2000  cost:  0.4549890313320597\n",
      "iter:  3000  cost:  0.4549890313320597\n",
      "iter:  4000  cost:  0.4549890313320597\n",
      "iter:  5000  cost:  0.4549890313320597\n",
      "iter:  6000  cost:  0.4549890313320597\n",
      "iter:  7000  cost:  0.4549890313320597\n",
      "iter:  8000  cost:  0.4549890313320597\n",
      "iter:  9000  cost:  0.4549890313320597\n"
     ]
    }
   ],
   "source": [
    "personal_weights, personal_cost_history = train(features, actual_personal_labels, weights, 0.35, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_predictions = predict(features, weights)\n",
    "personal_predicted_labels = classify(personal_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.5731219626350369\n",
      "iter:  1000  cost:  0.5548489591124812\n",
      "iter:  2000  cost:  0.554848959112481\n",
      "iter:  3000  cost:  0.554848959112481\n",
      "iter:  4000  cost:  0.554848959112481\n",
      "iter:  5000  cost:  0.554848959112481\n",
      "iter:  6000  cost:  0.554848959112481\n",
      "iter:  7000  cost:  0.554848959112481\n",
      "iter:  8000  cost:  0.554848959112481\n",
      "iter:  9000  cost:  0.554848959112481\n"
     ]
    }
   ],
   "source": [
    "vehicle_weights, vehicle_cost_history = train(features, actual_vehicles_labels, weights, 0.35, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_predictions = predict(features, weights)\n",
    "vehicle_predicted_labels = classify(vehicle_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies For Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Model: 0.9375 \n",
      " Electronic Model: 0.81125 \n",
      " For-the-home Model: 0.725 \n",
      " Hobbies Model: 0.90375 \n",
      " Personal Model: 0.8625 \n",
      " Vehicle Model: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Business Model:\",accuracy(business_predicted_labels, actual_business_labels),\"\\n\",\n",
    "      \"Electronic Model:\", accuracy(electronic_predicted_labels, actual_electronic_devices_labels),\"\\n\",\n",
    "      \"For-the-home Model:\", accuracy(for_the_home_predicted_labels, actual_for_the_home_labels),\"\\n\",\n",
    "      \"Hobbies Model:\", accuracy(hobbies_predicted_labels, actual_leisure_hobbies_labels),\"\\n\",\n",
    "      \"Personal Model:\", accuracy(personal_predicted_labels, actual_personal_labels),\"\\n\",\n",
    "      \"Vehicle Model:\", accuracy(vehicle_predicted_labels, actual_vehicles_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Using softmax to assign a class to each text sample\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning values to each text sample using predictions acquired for each model and softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14959185475532819\n",
      "0.2902197105806271\n",
      "0.3471917070385001\n",
      "0.2510124228975926\n",
      "0.25158763926172684\n",
      "0.36510075820391613\n",
      "[0.14653979694767963, 0.16866675408535248, 0.17855503898943906, 0.16218174858754006, 0.1622750650192878, 0.18178159637070088]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(business_predictions[0])\n",
    "print(electronic_predictions[0])\n",
    "print(for_the_home_predictions[0])\n",
    "print(hobbies_predictions[0])\n",
    "print(personal_predictions[0])\n",
    "print(vehicle_predictions[0])\n",
    "first_prediction = [business_predictions[0], electronic_predictions[0], for_the_home_predictions[0], \n",
    "              hobbies_predictions[0], personal_predictions[0], vehicle_predictions[0]]\n",
    "probs = softmax(first_prediction).tolist()\n",
    "print(probs)\n",
    "print(probs.index(max(probs)))\n",
    "# print(softmax(first_prediction).sum())\n",
    "def multiclass_predictor(business_predictions, electronic_predictions, for_the_home_predictions, \n",
    "                 hobbies_predictions, personal_predictions, vehicle_predictions):\n",
    "    \"\"\"\n",
    "    In this method, given the predictions done by each binary classifier, we assign a class to each text sample\n",
    "    \"\"\"  \n",
    "    predicted_categories = []\n",
    "    for i in range(len(business_predictions)):\n",
    "        prediction = [business_predictions[i], electronic_predictions[i], for_the_home_predictions[i], \n",
    "              hobbies_predictions[i], personal_predictions[i], vehicle_predictions[i]] #list containing predictions\n",
    "        probs = softmax(prediction).tolist() # a list of 6 values which each element rpresents the probability for that class\n",
    "        predicted_categories.append(probs.index(max(probs))) #assigning the maximum probability as category\n",
    "        \n",
    "    return predicted_categories\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = multiclass_predictor(business_predictions, electronic_predictions, for_the_home_predictions, \n",
    "                 hobbies_predictions, personal_predictions, vehicle_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of the final model\n",
    "final_predictions = np.array(final_predictions)\n",
    "Y_train = np.array(Y_train)\n",
    "final_model_accuracy = accuracy(final_predictions, Y_train)\n",
    "print(final_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n",
      "5 2\n",
      "5 2\n",
      "5 2\n",
      "5 2\n",
      "4 5\n",
      "1 5\n",
      "4 5\n",
      "2 2\n",
      "3 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(Y_train[i], final_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cross_entropy_loss_function(predicted_y, actual_y):\n",
    "    \"\"\"\n",
    "    cross entropy loss function calculates the distance between predicted output, and true output helping us to update our \n",
    "    weights and threshold, to have better predictions.\n",
    "    predicted_y : the predicted output\n",
    "    actual_y : the actual output\n",
    "    \"\"\"   \n",
    "    return -(actual_y * math.log(predicted_y) + (1 - actual_y) * math.log(1 - predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(sigmoid, numerical_X_train, actual_y):\n",
    "    \"\"\"\n",
    "    gradient descent algorithm, helps updating the wights.\n",
    "    sigmoid : the predicted y, more precisely, the probability of being in the class\n",
    "    numerical_X_train : the input data\n",
    "    actual_y : the actual output\n",
    "    \"\"\"  \n",
    "    derivatives = []\n",
    "    for i in range(len(numerical_X_train)):\n",
    "        corresponding_input_value = numerical_X_train[i]\n",
    "        derivatives.append((sigmoid - actual_y) * corresponding_input_value)\n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(w, b, X, Y, learning_rate, previous_cost):\n",
    "    \"\"\"\n",
    "    this method is used to update the weights and the threshold \n",
    "    w : the list of weights\n",
    "    b : the threshold\n",
    "    X : the input data, comes from a sample text\n",
    "    learning_rate : the rate in which we wish to change our weights and threshold\n",
    "    previous_cost : the cost before the updating\n",
    "    \"\"\"   \n",
    "    latest_w = w\n",
    "    latest_b = b\n",
    "    w_deriv = 0 #derivative of the weights\n",
    "    b_deriv = 0 #derivative of the threshold\n",
    "    N = len(X) #the length of the input data\n",
    "    for i in range(N):\n",
    "        # Calculate partial derivatives\n",
    "        # -2x(y - (wx + b))\n",
    "        w_deriv += -2*X[i] * (Y - (w[i]*X[i] + b))\n",
    "        # We subtract because the derivatives point in direction of steepest ascent\n",
    "        w[i] -= (w_deriv / float(N)) * learning_rate\n",
    "        \n",
    "    # -2(y - (wx + b))\n",
    "    b_deriv += -2*(Y - (np.mean(w)*X[0] + b))\n",
    "    b -= (b_deriv / float(N)) * learning_rate\n",
    "    z = weighted_sum_of_the_evidence_for_class(X, w, b) #calculating the weighted sum of the evidence for class\n",
    "    probability_of_being_in_class = sigmoid(z) #calculating the probability of being in that specific class\n",
    "    new_cost = calculate_cross_entropy_loss_function(probability_of_being_in_class, Y) #calculating the cost\n",
    "    if(new_cost > previous_cost):\n",
    "        w, b = latest_w, latest_b\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_true_positive(y_true, y_pred, category):\n",
    "    \"\"\"\n",
    "    This method calculates the number of correct positive predictions for a specific class\n",
    "    y_true : the list containing actual outputs\n",
    "    y_pred : the list containing predicted outputs\n",
    "    \"\"\"  \n",
    "    true_positives = 0\n",
    "    length_of_data = len(y_true)\n",
    "    #loop over the actual outputs and if the category in y_pred was also that specific class,\n",
    "    #this means that the model correctly predicted positively\n",
    "    for i in range(length_of_data): \n",
    "        if y_true[i] == category:\n",
    "            if y_pred[i] == category:\n",
    "                true_positives += 1 \n",
    "    return true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_true_negative(y_true, y_pred, category):\n",
    "    \"\"\"\n",
    "    This method calculates the number of correct negative predictions for a specific class\n",
    "    y_true : the list containing actual outputs\n",
    "    y_pred : the list containing predicted outputs\n",
    "    \"\"\" \n",
    "    true_negatives = 0\n",
    "    length_of_data = len(y_true)\n",
    "    #loop over the actual outputs and if the category was not that specific class, and also the y_pred was different\n",
    "    #this means that the model correctly predicted negatively\n",
    "    for i in range(length_of_data): \n",
    "        if y_true[i] != category:\n",
    "            if y_pred[i] != category:\n",
    "                true_negatives += 1 \n",
    "    return true_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_false_positive(y_true, y_pred, category):\n",
    "    \"\"\"\n",
    "    This method calculates the number of false positive predictions for a specific class\n",
    "    y_true : the list containing actual outputs\n",
    "    y_pred : the list containing predicted outputs\n",
    "    \"\"\" \n",
    "    false_positives = 0\n",
    "    length_of_data = len(y_true)\n",
    "    #loop over the predicted outputs; if the predicted output was category but the actual output (y_true) was not\n",
    "    #this means that the model falsely predicted positively\n",
    "    for i in range(length_of_data): \n",
    "        if y_pred[i] == category:\n",
    "            if y_true[i] != category:\n",
    "                false_positives += 1 \n",
    "    return false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_false_negative(y_true, y_pred, category):\n",
    "    \"\"\"\n",
    "    This method calculates the number of false negative predictions for a specific class\n",
    "    y_true : the list containing actual outputs\n",
    "    y_pred : the list containing predicted outputs\n",
    "    \"\"\" \n",
    "    false_negatives = 0\n",
    "    length_of_data = len(y_true)\n",
    "    #loop over the actual outputs and if the category was that specific class, and also the y_pred was different\n",
    "    #this means that the model falsely predicted negatively\n",
    "    for i in range(length_of_data): \n",
    "        if y_true[i] == category:\n",
    "            if y_pred[i] != category:\n",
    "                false_negatives += 1 \n",
    "    return false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(true_positive, true_negative, false_positive, false_negative):\n",
    "    \"\"\"\n",
    "    This method calculates the accuracy of the model for a specific class\n",
    "    true_positive : the samples that were positive and were predicted correctly\n",
    "    true_negative : the samples that were negative and were predicted correctly\n",
    "    false_positive : the samples that were negative and were falsely predicted as positive\n",
    "    false_negative : the samples that were positive and were falsely predicted as negative\n",
    "    \"\"\"  \n",
    "    accuracy = 0.0\n",
    "    accuracy = round((true_positive + true_negative)/(true_positive + true_negative + false_positive + false_negative), 3)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percision(true_positive, false_positive):\n",
    "    \"\"\"\n",
    "    This method calculates the percision of the model for a specific class\n",
    "    true_positive : the samples that were positive and were predicted correctly\n",
    "    false_positive : the samples that were negative and were falsely predicted as positive\n",
    "    \"\"\"  \n",
    "    percision = 0.0\n",
    "    percision = round(true_positive/(true_positive + false_positive) , 3)\n",
    "    return percision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(true_positive, false_negative):\n",
    "    \"\"\"\n",
    "    This method calculates the recall of the model for a specific class\n",
    "    true_positive : the samples that were positive and were predicted correctly\n",
    "    false_negative : the samples that were positive and were falsely predicted as negative\n",
    "    \"\"\"  \n",
    "    recall = 0.0\n",
    "    recall = round(true_positive/(true_positive + false_negative) , 3)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(recall, percision):\n",
    "    \"\"\"\n",
    "    This method calculates the f1 score of the model for a specific class\n",
    "    percision : the percision of the model for that class\n",
    "    recall : the recall of the model for that class\n",
    "    \"\"\"  \n",
    "    f1_score = 0.0\n",
    "    f1_score = round((2 * recall * percision)/(recall + percision) , 3)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_support(y_true, category):\n",
    "    \"\"\"\n",
    "    This method calculates the number of samples belong to a specific category in the y_true\n",
    "    y_true : the list containing actual outputs\n",
    "    category : the category that we are counting the number of\n",
    "    \"\"\"  \n",
    "    count = 0\n",
    "    length_of_data = len(y_true)\n",
    "    for i in range(length_of_data):\n",
    "        if y_true[i] == category:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_macro_average(f1_arr, percision_arr, recall_arr):\n",
    "    \"\"\"\n",
    "    An arithmetic mean of per-class F1, percision, and recall\n",
    "    f1_arr : a list containing f1_scores per class\n",
    "    percision_arr : a list containing percision per class\n",
    "    recall_arr : a list containing recall per class\n",
    "    \"\"\" \n",
    "    macro_averaged_f1 = round(np.mean(f1_arr), 3)\n",
    "    macro_averaged_percision = round(np.mean(percision_arr), 3)\n",
    "    macro_averaged_recall = round(np.mean(recall_arr), 3)\n",
    "    return macro_averaged_f1, macro_averaged_percision, macro_averaged_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_average(f1_arr, percision_arr, recall_arr, y_true):\n",
    "    \"\"\"\n",
    "    An arithmetic mean of per-class F1, percision, and recall, but also weights the score of each class by \n",
    "    the number of samplesfrom that class. This method works well based on the assumption that the f1_arr, \n",
    "    percision_arr, and recall_arr are given based on the alphabetic sort of their categories.\n",
    "    f1_arr : a list containing f1_scores per class\n",
    "    percision_arr : a list containing percision per class\n",
    "    recall_arr : a list containing recall per class\n",
    "    y_true : the list containing actual outputs\n",
    "    \"\"\" \n",
    "    samples_length = len(y_true)\n",
    "    counts = [] #a list containing the number of samples in each category\n",
    "    myset = set(y_true) #converting to set\n",
    "    categories = list(myset) #categories\n",
    "    sorted_categories = sorted(categories)\n",
    "#     print(sorted_categories)\n",
    "    \n",
    "    for i in range(len(categories)):\n",
    "        counts.append(y_true.count(sorted_categories[i]))\n",
    "#     print(counts)\n",
    "    f1 = 0\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "#     for i in range(len(f1_arr)):\n",
    "#         print(f1_arr[i], \" \", counts[i])\n",
    "    for i in range(len(f1_arr)):\n",
    "        f1 += (f1_arr[i] * counts[i])  \n",
    "        prec += (percision_arr[i] * counts[i])\n",
    "        rec += (recall_arr[i] * counts[i])\n",
    "    weighted_f1 = round(f1/samples_length, 3)  \n",
    "    weighted_percision = round(prec/samples_length, 3)\n",
    "    weighted_recall = round(rec/samples_length, 3)\n",
    "    \n",
    "    return weighted_f1, weighted_percision, weighted_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_micro_average(confusion_matrix):\n",
    "    \"\"\"\n",
    "    The following always holds true for the micro-F1 case:\n",
    "    micro-F1 = micro_percision = micro_recall = accuracy\n",
    "    We first calculate micro_percision and micro_recall and then combine the two\n",
    "    f1_arr : a list containing f1_scores per class\n",
    "    percision_arr : a list containing percision per class\n",
    "    recall_arr : a list containing recall per class\n",
    "    y_true : the list containing actual outputs\n",
    "    \"\"\" \n",
    "    #in multi-class, all the correctly predicted samples are true positives.\n",
    "    #gettin the diagonal\n",
    "    true_positives = 0\n",
    "    j = 0\n",
    "    for i in range(len(confusion_matrix)):\n",
    "        true_positives += confusion_matrix[i][j]\n",
    "        j += 1\n",
    "    \n",
    "#     print(true_positives)\n",
    "    #each prediction error is a false positive for the class that we predicted\n",
    "    #again, the total number of false negatives is the total number of prediction errors\n",
    "    #false_negatives = false_positives\n",
    "    false_positives = 0\n",
    "    for i in range(len(confusion_matrix)): #looping over the confusion matrix\n",
    "        for j in range(len(confusion_matrix)):\n",
    "            if i != j:  #passing the diagonal\n",
    "                false_positives += confusion_matrix[i][j]\n",
    "#     print(false_positives)    \n",
    "    accuracy = true_positives/(true_positives + false_positives)  \n",
    "    return round(accuracy, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0]\n",
      " [1 1 0 1 0 0]\n",
      " [0 0 1 1 0 0]\n",
      " [0 0 0 2 0 0]\n",
      " [1 0 0 0 1 0]\n",
      " [0 0 0 0 2 3]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        businesses      0.333     0.333     0.333         3\n",
      "electronic-devices      0.500     0.333     0.400         3\n",
      "      for-the-home      0.500     0.500     0.500         2\n",
      "   leisure-hobbies      0.500     1.000     0.667         2\n",
      "          personal      0.333     0.500     0.400         2\n",
      "          vehicles      1.000     0.600     0.750         5\n",
      "\n",
      "          accuracy                          0.529        17\n",
      "         macro avg      0.528     0.544     0.508        17\n",
      "      weighted avg      0.598     0.529     0.534        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Constants\n",
    "B = \"businesses\"\n",
    "E = \"electronic-devices\"\n",
    "F = \"for-the-home\"\n",
    "L = \"leisure-hobbies\"\n",
    "P = \"personal\"\n",
    "V = \"vehicles\"\n",
    "\n",
    "# True values\n",
    "y_true = [B, E, B, E, F, L, V, V, V, P, V, B, E, F, L, P, V]\n",
    "# Predicted values\n",
    "y_pred = [E, B, F, L, L, L, V, P, P, B, V, B, E, F, L, P, V]\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1 1]\n",
      " [6 2 2]\n",
      " [3 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat      0.308     0.667     0.421         6\n",
      "        Fish      0.667     0.200     0.308        10\n",
      "         Hen      0.667     0.667     0.667         9\n",
      "\n",
      "    accuracy                          0.480        25\n",
      "   macro avg      0.547     0.511     0.465        25\n",
      "weighted avg      0.581     0.480     0.464        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Constants\n",
    "C=\"Cat\"\n",
    "F=\"Fish\"\n",
    "H=\"Hen\"\n",
    "\n",
    "# True values\n",
    "y_true = [C,C,C,C,C,C, F,F,F,F,F,F,F,F,F,F, H,H,H,H,H,H,H,H,H]\n",
    "# Predicted values\n",
    "y_pred = [C,C,C,C,H,F, C,C,C,C,C,C,H,H,F,F, C,C,C,H,H,H,H,H,H]\n",
    "\n",
    "# Print the confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the category of the previous four calculations for TP, TN, FP, FN, \n",
    "# the acuracy, percision, recall and f1 score will be calculated for the same category\n",
    "true_positive = calculate_true_positive(y_true, y_pred, C) \n",
    "true_negative = calculate_true_negative(y_true, y_pred, C)\n",
    "false_positive = calculate_false_positive(y_true, y_pred, C)\n",
    "false_negative = calculate_false_negative(y_true, y_pred, C)\n",
    "accuracy_for_cat = calculate_accuracy(true_positive, true_negative, false_positive, false_negative)\n",
    "percision_for_cat = calculate_percision(true_positive, false_positive)\n",
    "recall_for_cat = calculate_recall(true_positive, false_negative)\n",
    "f1_score_for_cat = calculate_f1_score(recall_for_cat, percision_for_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4   10   9   2\n",
      "0.56   0.308   0.667   0.421\n"
     ]
    }
   ],
   "source": [
    "print(true_positive, \" \", true_negative, \" \", false_positive, \" \", false_negative) \n",
    "print(accuracy_for_cat, \" \", percision_for_cat, \" \", recall_for_cat, \" \", f1_score_for_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = [0.421, 0.308, 0.667]\n",
    "percision = [0.308, 0.667, 0.667]\n",
    "recall = [0.667, 0.200, 0.667]\n",
    "macro_f1, macro_percision, macro_recall = calculate_macro_average(f1, percision, recall)\n",
    "weighted_f1, weighted_percision, weighted_recall = calculate_weighted_average(f1, percision, recall, y_true)\n",
    "accuracy =  calculate_micro_average(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = [0.333, 0.400, 0.500, 0.667, 0.400, 0.750]\n",
    "percision = [0.333, 0.500, 0.500, 0.500, 0.333, 1.000]\n",
    "recall = [0.333, 0.333, 0.500, 1.000, 0.500, 0.600]\n",
    "macro_f1, macro_percision, macro_recall = calculate_macro_average(f1, percision, recall)\n",
    "weighted_f1, weighted_percision, weighted_recall = calculate_weighted_average(f1, percision, recall, y_true)\n",
    "accuracy =  calculate_micro_average(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508   0.528   0.544\n"
     ]
    }
   ],
   "source": [
    "print(macro_f1, \" \", macro_percision, \" \", macro_recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534   0.598   0.529\n"
     ]
    }
   ],
   "source": [
    "print(weighted_f1, \" \", weighted_percision, \" \", weighted_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the average methods need fixing to do the job for other dataframes.\n",
    "the confusion matrix function should be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0  34   0   0  16]\n",
      " [  0   0  99   0   0  52]\n",
      " [  0   0 160   0   0  60]\n",
      " [  0   0  45   0   0  32]\n",
      " [  0   0  77   0   0  33]\n",
      " [  0   0 112   0   0  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000        50\n",
      "           1      0.000     0.000     0.000       151\n",
      "           2      0.304     0.727     0.428       220\n",
      "           3      0.000     0.000     0.000        77\n",
      "           4      0.000     0.000     0.000       110\n",
      "           5      0.293     0.417     0.344       192\n",
      "\n",
      "    accuracy                          0.300       800\n",
      "   macro avg      0.099     0.191     0.129       800\n",
      "weighted avg      0.154     0.300     0.200       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(Y_train, final_predictions))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(Y_train, final_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of confusion matrix\n",
    "import pandas as pd\n",
    "y_actu = pd.Series(Y_train, name='Actual')\n",
    "y_pred = pd.Series(final_predictions, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>33</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>80</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>527</td>\n",
       "      <td>273</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    2    5  All\n",
       "Actual                  \n",
       "0          34   16   50 \n",
       "1          99   52   151\n",
       "2          160  60   220\n",
       "3          45   32   77 \n",
       "4          77   33   110\n",
       "5          112  80   192\n",
       "All        527  273  800"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcularing the accuracy for validation set\n",
    "descriptions = validationset['desc']\n",
    "titles = validationset['title']\n",
    "cleared_descriptions = preprocessing(descriptions.head(1000)) #preprocessed descriptions\n",
    "cleared_titles = preprocessing(titles.head(1000)) #preprocessed titles\n",
    "#the following are all lists\n",
    "#A list containing numerical title and description for each text sample in the training set\n",
    "titles, descriptions = get_numerical_features(non_numerical_title, non_numerical_description) \n",
    "Y = categorizer(non_numerical_Y) #A list containing an integer for the category in cat1\n",
    "title_train, title_test, description_train, description_test, Y_train, Y_test = train_test_split(\n",
    "        titles, descriptions, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thes are the desired outputs only for the train part of the trainset in the 6 class of categories\n",
    "#We need these values in order to train our model to predict the X values in the validation set\n",
    "Y_train0 = calculate_businesses(Y_train) #o0 is a list which is one when the cat1 in the Y_train is businesses and zero otherwise\n",
    "Y_train1 = calculate_electronic_devices(Y_train) #o1 is a list which is one when the cat1 in the Y_train is electronic-devices and zero otherwise\n",
    "Y_train2 = calculate_for_the_home(Y_train) #o2 is a list which is one when the cat1 in the Y_train is for-the-home and zero otherwise\n",
    "Y_train3 = calculate_leisure_hobbies(Y_train) #o3 is a list which is one when the cat1 in the Y_train is leisure-hobbies and zero otherwise\n",
    "Y_train4 = calculate_personal(Y_train) #o4 is a list which is one when the cat1 in the Y_train is personal and zero otherwise\n",
    "Y_train5 = calculate_vehicles(Y_train) #o5 is a list which is one when the cat1 in the Y_train is vehicles and zero otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2831345  0.42813806]\n",
      "[2.20611815 0.575463  ]\n",
      "[2.81329034 1.97718869]\n",
      "[1.00838878 1.42689962]\n",
      "[2.31509918 0.53565907]\n",
      "(800, 2)\n",
      "(2,)\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression by determining the features and weights\n",
    "feature = []\n",
    "a = []\n",
    "for i in range(len(title_train)):\n",
    "    a.append(title_train[i])\n",
    "    a.append(description_train[i])\n",
    "    feature.append(a)    \n",
    "    a = []\n",
    "\n",
    "w0 = np.random.uniform(low = 0, high = 1) #initializing the wight0 with a random uniform real number\n",
    "w1 = np.random.uniform(low = 0, high = 1) #initializing the wight1 with a random uniform real number\n",
    "w2 = np.random.uniform(low = 0, high = 1) #initializing the wight2 with a random uniform real number\n",
    "\n",
    "weights = np.array([w1, w2])\n",
    "features = np.array(feature) #features is a 2d numpy array that has title_train as first column and description_train as the second \n",
    "\n",
    "\n",
    "# z = w0 + w1*title + w2*description\n",
    "\n",
    "for i in range(5): #printing some features and their corresponding labels\n",
    "    print(features[i])\n",
    "\n",
    "print(features.shape)\n",
    "print(weights.shape)\n",
    "z = np.dot(features, weights)\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING THE MODELS TO PREDICT EACH CATEGORY (y = w1 x title + w2 x description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "(800,)\n",
      "(800,)\n",
      "(800,)\n",
      "(800,)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing logistic regression for businesses\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train0[i]) #businesses\n",
    "actual_business_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_business_labels.shape)\n",
    "\n",
    "# Initializing logistic regression for electronic_devices\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train1[i]) #electronic_devices\n",
    "actual_electronic_devices_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_electronic_devices_labels.shape)\n",
    "\n",
    "# Initializing logistic regression for for_the_home\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train2[i]) #for_the_home\n",
    "actual_for_the_home_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_for_the_home_labels.shape)\n",
    "\n",
    "# Initializing logistic regression for leisure_hobbies\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train3[i]) #leisure_hobbies\n",
    "actual_leisure_hobbies_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_leisure_hobbies_labels.shape)\n",
    "\n",
    "# Initializing logistic regression for personal\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train4[i]) #personal\n",
    "actual_personal_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_personal_labels.shape)\n",
    "\n",
    "# Initializing logistic regression for vehicles\n",
    "label = []\n",
    "for i in range(len(title_train)):\n",
    "    label.append(Y_train5[i]) #vehicles\n",
    "actual_vehicles_labels = np.array(label) #labels are the desires output or Y_train also an numpy array\n",
    "print(actual_vehicles_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.2924488354336976\n",
      "iter:  1000  cost:  0.2924488354336976\n",
      "iter:  2000  cost:  0.2924488354336976\n",
      "iter:  3000  cost:  0.2924488354336976\n",
      "iter:  4000  cost:  0.2924488354336976\n",
      "iter:  5000  cost:  0.2924488354336976\n",
      "iter:  6000  cost:  0.2924488354336976\n",
      "iter:  7000  cost:  0.2924488354336976\n",
      "iter:  8000  cost:  0.2924488354336976\n",
      "iter:  9000  cost:  0.2924488354336976\n"
     ]
    }
   ],
   "source": [
    "business_weights, business_cost_history = train(features, actual_business_labels, weights, 0.35, 10000)\n",
    "business_predictions = predict(features, weights)\n",
    "business_predicted_labels = classify(business_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.547466200979262\n",
      "iter:  1000  cost:  0.49741998271086735\n",
      "iter:  2000  cost:  0.4974199827108673\n",
      "iter:  3000  cost:  0.4974199827108673\n",
      "iter:  4000  cost:  0.4974199827108673\n",
      "iter:  5000  cost:  0.4974199827108673\n",
      "iter:  6000  cost:  0.4974199827108673\n",
      "iter:  7000  cost:  0.4974199827108673\n",
      "iter:  8000  cost:  0.4974199827108673\n",
      "iter:  9000  cost:  0.4974199827108673\n"
     ]
    }
   ],
   "source": [
    "electronic_weights, electronic_cost_history = train(features, actual_electronic_devices_labels, weights, 0.35, 10000)\n",
    "electronic_predictions = predict(features, weights)\n",
    "electronic_predicted_labels = classify(electronic_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.6406565983344934\n",
      "iter:  1000  cost:  0.6081959318058575\n",
      "iter:  2000  cost:  0.6081959318058575\n",
      "iter:  3000  cost:  0.6081959318058575\n",
      "iter:  4000  cost:  0.6081959318058575\n",
      "iter:  5000  cost:  0.6081959318058575\n",
      "iter:  6000  cost:  0.6081959318058575\n",
      "iter:  7000  cost:  0.6081959318058575\n",
      "iter:  8000  cost:  0.6081959318058575\n",
      "iter:  9000  cost:  0.6081959318058575\n"
     ]
    }
   ],
   "source": [
    "for_the_home_weights, for_the_home_cost_history = train(features, actual_for_the_home_labels, weights, 0.35, 10000)\n",
    "for_the_home_predictions = predict(features, weights)\n",
    "for_the_home_predicted_labels = classify(for_the_home_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.44494496413397394\n",
      "iter:  1000  cost:  0.3662833083811688\n",
      "iter:  2000  cost:  0.3662833066838577\n",
      "iter:  3000  cost:  0.36628330668385756\n",
      "iter:  4000  cost:  0.36628330668385756\n",
      "iter:  5000  cost:  0.36628330668385756\n",
      "iter:  6000  cost:  0.36628330668385756\n",
      "iter:  7000  cost:  0.36628330668385756\n",
      "iter:  8000  cost:  0.36628330668385756\n",
      "iter:  9000  cost:  0.36628330668385756\n"
     ]
    }
   ],
   "source": [
    "hobbies_weights, hobbies_cost_history = train(features, actual_leisure_hobbies_labels, weights, 0.35, 10000)\n",
    "hobbies_predictions = predict(features, weights)\n",
    "hobbies_predicted_labels = classify(hobbies_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.5010844695611638\n",
      "iter:  1000  cost:  0.4522056238110062\n",
      "iter:  2000  cost:  0.4522056238110062\n",
      "iter:  3000  cost:  0.4522056238110062\n",
      "iter:  4000  cost:  0.4522056238110062\n",
      "iter:  5000  cost:  0.4522056238110062\n",
      "iter:  6000  cost:  0.4522056238110062\n",
      "iter:  7000  cost:  0.4522056238110062\n",
      "iter:  8000  cost:  0.4522056238110062\n",
      "iter:  9000  cost:  0.4522056238110062\n"
     ]
    }
   ],
   "source": [
    "personal_weights, personal_cost_history = train(features, actual_personal_labels, weights, 0.35, 10000)\n",
    "personal_predictions = predict(features, weights)\n",
    "personal_predicted_labels = classify(personal_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0  cost:  0.5745624667822271\n",
      "iter:  1000  cost:  0.5547552348243195\n",
      "iter:  2000  cost:  0.5547552348243195\n",
      "iter:  3000  cost:  0.5547552348243195\n",
      "iter:  4000  cost:  0.5547552348243195\n",
      "iter:  5000  cost:  0.5547552348243195\n",
      "iter:  6000  cost:  0.5547552348243195\n",
      "iter:  7000  cost:  0.5547552348243195\n",
      "iter:  8000  cost:  0.5547552348243195\n",
      "iter:  9000  cost:  0.5547552348243195\n"
     ]
    }
   ],
   "source": [
    "vehicle_weights, vehicle_cost_history = train(features, actual_vehicles_labels, weights, 0.35, 10000)\n",
    "vehicle_predictions = predict(features, weights)\n",
    "vehicle_predicted_labels = classify(vehicle_predictions) #labels predicted by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Model: 0.9375 \n",
      " Electronic Model: 0.81125 \n",
      " For-the-home Model: 0.725 \n",
      " Hobbies Model: 0.90375 \n",
      " Personal Model: 0.8625 \n",
      " Vehicle Model: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Business Model:\",accuracy(business_predicted_labels, actual_business_labels),\"\\n\",\n",
    "      \"Electronic Model:\", accuracy(electronic_predicted_labels, actual_electronic_devices_labels),\"\\n\",\n",
    "      \"For-the-home Model:\", accuracy(for_the_home_predicted_labels, actual_for_the_home_labels),\"\\n\",\n",
    "      \"Hobbies Model:\", accuracy(hobbies_predicted_labels, actual_leisure_hobbies_labels),\"\\n\",\n",
    "      \"Personal Model:\", accuracy(personal_predicted_labels, actual_personal_labels),\"\\n\",\n",
    "      \"Vehicle Model:\", accuracy(vehicle_predicted_labels, actual_vehicles_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29500000000000004\n",
      "4 5\n",
      "5 2\n",
      "5 2\n",
      "5 2\n",
      "5 5\n",
      "4 5\n",
      "1 5\n",
      "4 5\n",
      "2 2\n",
      "3 5\n"
     ]
    }
   ],
   "source": [
    "# multiclass prediction\n",
    "final_predictions = multiclass_predictor(business_predictions, electronic_predictions, for_the_home_predictions, \n",
    "                 hobbies_predictions, personal_predictions, vehicle_predictions)\n",
    "\n",
    "# Calculating the accuracy of the final model\n",
    "final_predictions = np.array(final_predictions)\n",
    "Y_train = np.array(Y_train)\n",
    "final_model_accuracy = accuracy(final_predictions, Y_train)\n",
    "print(final_model_accuracy)\n",
    "for i in range(10):\n",
    "    print(Y_train[i], final_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
